{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Encoders\n",
    "\n",
    "* Random Distributed Scalar Encoder\n",
    "* Date/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2013-12-02 21:15:00', 'value': 73.96732207},\n",
       " {'timestamp': '2013-12-02 21:20:00', 'value': 74.93588199999998},\n",
       " {'timestamp': '2013-12-02 21:25:00', 'value': 76.12416182},\n",
       " {'timestamp': '2013-12-02 21:30:00', 'value': 78.14070732},\n",
       " {'timestamp': '2013-12-02 21:35:00', 'value': 79.32983574}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/realKnownCause/machine_temperature_system_failure.csv')\n",
    "data = data.to_dict(orient='records')\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nupic.encoders.random_distributed_scalar import RandomDistributedScalarEncoder\n",
    "from nupic.encoders.scalar import ScalarEncoder\n",
    "\n",
    "#RandomDistributedScalarEncoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.96732207 =  [0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "74.935882 =  [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 21 bits with 3 active with buckets of size 5\n",
    "#vEnc = RandomDistributedScalarEncoder(n=21, w=3, resolution=0.1)\n",
    "vEnc = ScalarEncoder(n=21, w=3, minval=70, maxval=80, forced=True)\n",
    "#vEnc = ScalarEncoder(resolution=0.1, w=21, minval=60, maxval=100)\n",
    "\n",
    "print str(data[0]['value']) + \" = \", vEnc.encode(data[0]['value'])\n",
    "print str(data[1]['value']) + \" = \", vEnc.encode(data[1]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'[70:80]': ([[75.0, 75.0]], '75.00')}, ['[70:80]'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = vEnc.encode(75.123)\n",
    "print(enc)\n",
    "vEnc.decode(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from nupic.encoders.date import DateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 73.96732207},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 74.93588199999998},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 76.12416182},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 78.14070732},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       "  'inputVal': 79.32983574}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode some observation\n",
    "\n",
    "obs = []\n",
    "inputVal = []\n",
    "inputSDR = []\n",
    "\n",
    "for i in xrange(5):\n",
    "    obs.append(i)\n",
    "    inputVal.append(data[i]['value'])\n",
    "    inputSDR.append(vEnc.encode(data[i]['value']))\n",
    "\n",
    "    \n",
    "track = pd.DataFrame({'inputVal':inputVal, 'inputSDR':inputSDR}, index=obs).to_dict(orient='records')\n",
    "track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStamp-obs1 =  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "TimeStamp-obs2 =  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "de = DateEncoder(season=5, weekend=1, dayOfWeek=7, timeOfDay=23) \n",
    "\n",
    "tsObs1 = datetime.datetime.strptime(data[0]['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "tsObs2 = datetime.datetime.strptime(data[1]['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print \"TimeStamp-obs1 = \", de.encode(tsObs1)\n",
    "print \"TimeStamp-obs2 = \", de.encode(tsObs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print sum(de.encode(tsObs1))\n",
    "print sum(de.encode(tsObs2))\n",
    "print sum(de.encode(tsObs1)*de.encode(tsObs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Spatial Pooler\n",
    "[link to wiki](http://nupic.docs.numenta.org/1.0.3/api/algorithms/spatial-pooling.html#nupic.algorithms.spatial_pooler.SpatialPooler)\n",
    "\n",
    "First we will check SP only on `Value`, without `Timestamp` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.spatial_pooler import SpatialPooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print track[0]['inputSDR']\n",
    "print len(track[0]['inputSDR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define SP properties\n",
    "sp = SpatialPooler(inputDimensions=(len(track[0]['inputSDR']),),\n",
    "                   columnDimensions=(5,),\n",
    "                   potentialRadius=15,\n",
    "                   numActiveColumnsPerInhArea=1,\n",
    "                   globalInhibition=True,\n",
    "                   synPermActiveInc=0,\n",
    "                   #potentialPct=.80,\n",
    "                   #stimulusThreshold=1, \n",
    "                   synPermConnected=.5,\n",
    "                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP form:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]),\n",
       " array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]),\n",
       " array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialie SP\n",
    "cols = []\n",
    "connections = []\n",
    "\n",
    "for col in xrange(sp.getColumnDimensions()):\n",
    "    connected = np.zeros(len(track[0]['inputSDR']), dtype=\"int\")\n",
    "    sp.getConnectedSynapses(col, connected)\n",
    "    cols.append(col)\n",
    "    connections.append(connected)\n",
    "\n",
    "spSDR = dict(zip(cols, connections))\n",
    "\n",
    "print \"SP form:\"\n",
    "spSDR.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The active bits (min-columns) are set by calculating the *overlapping score* with the input vector.  \n",
    "*Overalpping score* = `inputSDR` * `spSDR\\[column]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The active column for every `inputSDR` is:\n",
      "obs0, overlap:  [2, 0, 0, 0, 0], Active col:  0\n",
      "obs1, overlap:  [0, 1, 1, 0, 0], Active col:  1\n",
      "obs2, overlap:  [0, 2, 1, 0, 1], Active col:  1\n",
      "obs3, overlap:  [0, 1, 2, 0, 1], Active col:  2\n",
      "obs4, overlap:  [0, 0, 1, 1, 0], Active col:  2\n"
     ]
    }
   ],
   "source": [
    "# calculate ACTIVE columns: cols with higher overlap for every input SDR \n",
    "print \"The active column for every `inputSDR` is:\"\n",
    "\n",
    "for i in xrange(len(track)):\n",
    "    overlap = []\n",
    "    for j in spSDR:\n",
    "        overlap.append(sum(track[i]['inputSDR'] * spSDR.values()[j]))\n",
    "    o = overlap.index(max(overlap))\n",
    "    \n",
    "    print \"obs\" + str(i) + \", overlap: \", str(overlap) +  \", Active col: \", str(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute()` should do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs0, Active col:  [1 0 0 0 0]\n",
      "obs1, Active col:  [0 0 1 0 0]\n",
      "obs2, Active col:  [0 1 0 0 0]\n",
      "obs3, Active col:  [0 0 1 0 0]\n",
      "obs4, Active col:  [0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(track)):\n",
    "    output = np.zeros(sp.getColumnDimensions(), dtype=\"int\")\n",
    "    sp.compute(track[i]['inputSDR'], learn=True, activeArray=output)\n",
    "    track[i]['sp_active'] = output.argmax() #save to dict\n",
    "    \n",
    "    print \"obs\" + str(i) + \", Active col: \", str(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `max()` in case of a tie, returns the first `maxVal` encountered.  \n",
    "`sp.compute` apparently the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_max_index(lista):\n",
    "    '''\n",
    "    max() function in case of a tie returns the first max value found.\n",
    "    This function, in case of tie returns the last max value in our list.\n",
    "    \n",
    "    input: list\n",
    "    output: int, index last max value \n",
    "    '''\n",
    "    \n",
    "    l = len(lista)\n",
    "    lista.reverse()\n",
    "    i = lista.index(max(lista))\n",
    "    lista.reverse()\n",
    "    return (l-i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs0, overlap:  [2, 0, 0, 0, 0], Active col:  0\n",
      "obs1, overlap:  [0, 1, 1, 0, 0], Active col:  2\n",
      "obs2, overlap:  [0, 2, 1, 0, 1], Active col:  1\n",
      "obs3, overlap:  [0, 1, 2, 0, 1], Active col:  2\n",
      "obs4, overlap:  [0, 0, 1, 1, 0], Active col:  3\n"
     ]
    }
   ],
   "source": [
    "# calculate ACTIVE columns: cols with higher overlap for every input SDR \n",
    "for i in xrange(len(track)):\n",
    "    overlap = []\n",
    "    for j in spSDR:\n",
    "        overlap.append(sum(track[i]['inputSDR'] * spSDR.values()[j]))\n",
    "    o = last_max_index(overlap)\n",
    "        \n",
    "    print \"obs\" + str(i) + \", overlap: \", str(overlap) +  \", Active col: \", str(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the values matches with `sp.compute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for _ in xrange(1000):\n",
    "    sp.compute(track[1]['inputSDR'], learn=True, activeArray=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE Column:  [0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print \"ACTIVE Column: \", output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `learn=False`, the synapses will not be updated, so that the output never chance.\n",
    "Furthermore we set `SpatialPooler(synPermActiveInc=0, synPermInactiveDec=0)`, so that even with `learn=True` the SP is not able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spSDR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permanence\n",
    "permanence = []\n",
    "\n",
    "for i in xrange(sp.getColumnDimensions()):\n",
    "    p = []\n",
    "    sp.getPermanence(i, p)\n",
    "    permanence.append(np.array(p))\n",
    "\n",
    "# permanence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Permanence > Threshold` we have a connection to the *inputSDR*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing SP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputSDR:  [0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "SP active col:  [0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "Overlappin bits:  [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Pemanence winning col:  [ 0.          0.80418003  0.          0.          0.74185008  0.          0.\n",
      "  0.97499007  0.80207008  0.          0.32082     0.          0.37413001\n",
      "  0.55197006  0.98236006  0.          0.27287     0.44242004  0.          0.\n",
      "  1.        ]\n"
     ]
    }
   ],
   "source": [
    "print \"inputSDR: \", track[0]['inputSDR']\n",
    "print \"SP active col: \", spSDR[track[0]['sp_active']]\n",
    "print \"Overlappin bits: \", str(track[0]['inputSDR'] * spSDR[track[0]['sp_active']])\n",
    "print \"Pemanence winning col: \", permanence[track[0]['sp_active']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Temporal Pooler\n",
    "\n",
    "[link to wiki](http://nupic.docs.numenta.org/1.0.3/api/algorithms/sequence-memory.html#nupic.algorithms.backtracking_tm_cpp.BacktrackingTMCPP)\n",
    "SP output is TM input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nupic.algorithms.backtracking_tm import BacktrackingTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spSDR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the example we suggest to set `verbosity=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define TM properties\n",
    "# input vectors to feed TM: SP output is TM input and must be numberOfCols wide. \n",
    "tm = BacktrackingTM(numberOfCols=len(spSDR[0]), cellsPerColumn=3,\n",
    "                    initialPerm=0.5, connectedPerm=0.5,\n",
    "                    minThreshold=10, newSynapseCount=10,\n",
    "                    permanenceInc=0.1, permanenceDec=0.0,\n",
    "                    activationThreshold=2,\n",
    "                    globalDecay=0, burnIn=1,\n",
    "                    checkSynapseConsistency=False,\n",
    "                    pamLength=10,\n",
    "                    seed = 42,\n",
    "                    collectStats=True,\n",
    "                    #verbosity=5,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm0= tm.compute(spSDR[0], enableInference=True, enableLearn=True)\n",
    "tm0.shape\n",
    "tm0.reshape(21,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'curExtra': 0,\n",
       " 'curFalseNegativeScore': 1.0,\n",
       " 'curFalsePositiveScore': 0.0,\n",
       " 'curMissing': 5,\n",
       " 'curPredictionScore2': 0.0,\n",
       " 'falseNegativeAvg': 0,\n",
       " 'falsePositiveAvg': 0,\n",
       " 'nPredictions': 0,\n",
       " 'pctExtraAvg': 0,\n",
       " 'pctMissingAvg': 0,\n",
       " 'predictionScoreAvg2': 0,\n",
       " 'prevSequenceSignature': None,\n",
       " 'totalExtra': 0,\n",
       " 'totalMissing': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.getStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example1**\n",
    "`enableInference=True`, `enableLearn=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm4 = tm.compute(spSDR[4], enableInference=True, enableLearn=False)\n",
    "tm4.reshape(21,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**\n",
    "`enableInference=False`, `enableLearn=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm4 = tm.compute(spSDR[4], enableInference=False, enableLearn=True)\n",
    "tm4.reshape(21, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3** `enableInference=False`, `enableLearn=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm4 = tm.compute(spSDR[4], enableInference=True, enableLearn=True)\n",
    "tm4.reshape(21, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]),\n",
       " array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]),\n",
       " array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = spSDR\n",
    "x.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 3: send the  input to the temporal memory for learning\n",
    "# We repeat the sequence 10 times\n",
    "for i in range(10):\n",
    "\n",
    "    # Send each input in the sequence in order\n",
    "    for j in range(len(x)):\n",
    "\n",
    "        # The compute method performs one step of learning and/or inference. Note:\n",
    "        # here we just perform learning but you can perform prediction/inference and\n",
    "        # learning in the same step if you want (online learning).\n",
    "        tm_output = tm.compute(x[j], enableLearn=True, enableInference=True)\n",
    "        tm_output.reshape(21, 3)\n",
    "        # This function prints the segments associated with every cell.$$$$\n",
    "        # If you really want to understand the TP, uncomment this line. By following\n",
    "        # every step you can get an excellent understanding for exactly how the TP\n",
    "        # learns.\n",
    "        #tm.printCells()\n",
    "\n",
    "    # The reset command tells the TM that a sequence just ended and essentially\n",
    "    # zeros out all the states. It is not strictly necessary but it's a bit\n",
    "    # messier without resets, and the TM learns quicker with resets.\n",
    "    tm.reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------- 0 -----------\n",
      "Raw input vector\n",
      "0100000110 0000100000 1 \n",
      "\n",
      "All the active and predicted cells:\n",
      "\n",
      "Inference Active state\n",
      "0000000000 0000000000 0 \n",
      "0100000100 0000000000 0 \n",
      "0000000010 0000100000 1 \n",
      "Inference Predicted state\n",
      "0000000000 0000000000 0 \n",
      "0010001000 0110000000 0 \n",
      "1000010000 0001110000 0 \n",
      "\n",
      "\n",
      "The following columns are predicted by the temporal memory. This\n",
      "should correspond to columns in the *next* item in the sequence.\n",
      "[ 0  2  5  6 11 12 13 14 15] \n",
      "\n",
      "\n",
      "-------- 1 -----------\n",
      "Raw input vector\n",
      "1010001000 0101110000 0 \n",
      "\n",
      "All the active and predicted cells:\n",
      "\n",
      "Inference Active state\n",
      "0000000000 0000000000 0 \n",
      "0010001000 0100000000 0 \n",
      "1000000000 0001110000 0 \n",
      "Inference Predicted state\n",
      "0000000000 0000000000 0 \n",
      "0010000000 0000000100 0 \n",
      "0000000000 1010001000 1 \n",
      "\n",
      "\n",
      "The following columns are predicted by the temporal memory. This\n",
      "should correspond to columns in the *next* item in the sequence.\n",
      "[ 2 10 12 16 17 20] \n",
      "\n",
      "\n",
      "-------- 2 -----------\n",
      "Raw input vector\n",
      "0010000000 1010001100 1 \n",
      "\n",
      "All the active and predicted cells:\n",
      "\n",
      "Inference Active state\n",
      "0000000000 0000000000 0 \n",
      "0010000000 0000000100 0 \n",
      "0000000000 1010001000 1 \n",
      "Inference Predicted state\n",
      "0000000000 0000000000 0 \n",
      "1000110000 0000000001 0 \n",
      "0010000000 0000000000 0 \n",
      "\n",
      "\n",
      "The following columns are predicted by the temporal memory. This\n",
      "should correspond to columns in the *next* item in the sequence.\n",
      "[ 0  2  4  5 19] \n",
      "\n",
      "\n",
      "-------- 3 -----------\n",
      "Raw input vector\n",
      "1010110000 0000000001 0 \n",
      "\n",
      "All the active and predicted cells:\n",
      "\n",
      "Inference Active state\n",
      "0000000000 0000000000 0 \n",
      "1000110000 0000000001 0 \n",
      "0010000000 0000000000 0 \n",
      "Inference Predicted state\n",
      "0000000000 0000000000 0 \n",
      "0000010000 0000010000 0 \n",
      "0000000000 0010000000 0 \n",
      "\n",
      "\n",
      "The following columns are predicted by the temporal memory. This\n",
      "should correspond to columns in the *next* item in the sequence.\n",
      "[ 5 12 15] \n",
      "\n",
      "\n",
      "-------- 4 -----------\n",
      "Raw input vector\n",
      "0000010000 0010010000 0 \n",
      "\n",
      "All the active and predicted cells:\n",
      "\n",
      "Inference Active state\n",
      "0000000000 0000000000 0 \n",
      "0000010000 0000010000 0 \n",
      "0000000000 0010000000 0 \n",
      "Inference Predicted state\n",
      "0000000000 0000000000 0 \n",
      "0100000100 0000000000 0 \n",
      "0000000010 0000100000 1 \n",
      "\n",
      "\n",
      "The following columns are predicted by the temporal memory. This\n",
      "should correspond to columns in the *next* item in the sequence.\n",
      "[ 1  7  8 14 20] \n"
     ]
    }
   ],
   "source": [
    "# Step 4: send the same sequence of vectors and look at predictions made by\n",
    "# temporal memory\n",
    "\n",
    "# Utility routine for printing the input vector\n",
    "def formatRow(x):\n",
    "    s = ''\n",
    "    for c in range(len(x)):\n",
    "        if c > 0 and c % 10 == 0:\n",
    "            s += ' '\n",
    "        s += str(x[c])\n",
    "    s += ' '\n",
    "    return s\n",
    "\n",
    "for j in range(5):\n",
    "    print \"\\n\\n--------\",\"01234\"[j],\"-----------\"\n",
    "    print \"Raw input vector\\n\",formatRow(x[j])\n",
    "\n",
    "    # Send each vector to the TP, with learning turned off\n",
    "    tm.compute(x[j], enableLearn=True, enableInference=True)\n",
    "\n",
    "    # This method prints out the active state of each cell followed by the\n",
    "    # predicted state of each cell. For convenience the cells are grouped\n",
    "    # 10 at a time. When there are multiple cells per column the printout\n",
    "    # is arranged so the cells in a column are stacked together\n",
    "    #\n",
    "    # What you should notice is that the columns where active state is 1\n",
    "    # represent the SDR for the current input pattern and the columns where\n",
    "    # predicted state is 1 represent the SDR for the next expected pattern\n",
    "    print \"\\nAll the active and predicted cells:\"\n",
    "    tm.printStates(printPrevious=False, printLearnState=False)\n",
    "\n",
    "    # tm.getPredictedState() gets the predicted cells.\n",
    "    # predictedCells[c][i] represents the state of the i'th cell in the c'th\n",
    "    # column. To see if a column is predicted, we can simply take the OR\n",
    "    # across all the cells in that column. In numpy we can do this by taking\n",
    "    # the max along axis 1.\n",
    "    print \"\\n\\nThe following columns are predicted by the temporal memory. This\"\n",
    "    print \"should correspond to columns in the *next* item in the sequence.\"\n",
    "    predictedCells = tm.getPredictedState()\n",
    "    print formatRow(predictedCells.max(axis=1).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictedCells.T\n",
    "tm.getPredictedState().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate': array([[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]], dtype=float32), 't': array([[ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0.2,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0.2]], dtype=float32), 't-1': array([[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.33333334,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.33333334],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.33333334,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]], dtype=float32)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.cellConfidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackability - Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 73.96732207,\n",
       "  'sp_active': 0},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 74.93588199999998,\n",
       "  'sp_active': 2},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 76.12416182,\n",
       "  'sp_active': 1},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 78.14070732,\n",
       "  'sp_active': 2},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       "  'inputVal': 79.32983574,\n",
       "  'sp_active': 3}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input SDR can be Decoded up to a certain granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.96732207"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track[0]['inputVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[70:80]': ([[73.888888888888886, 73.888888888888886]], '73.89')},\n",
       " ['[70:80]'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vEnc.decode(track[0]['inputSDR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed SP with `sp.compute(track[i]['inputSDR'], learn=True, activeArray=output)`,  \n",
    "and then the *Temporal Pooler* `inputSDR[track[i]['sp_active']]` = active columns in TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackability - Backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate *TM output* by feeding in the active columns of the *SP*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spSDR[track[0]['sp_active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.compute(spSDR[track[0]['sp_active']], enableLearn=True, enableInference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return index for ACTIVE columns in TM: \n",
    "tmActive = []\n",
    "\n",
    "for i in range(tm.infActiveState['t'].shape[0]):\n",
    "    # assign 1 if any 1 (active cell) in the column,\n",
    "    # 0 otherwise\n",
    "    if np.any(tm.infActiveState['t'][i]>0):\n",
    "        tmActive.append(1)\n",
    "    else:\n",
    "        tmActive.append(0)\n",
    "# return index of active Columns        \n",
    "tm_active = np.flatnonzero(np.array(tmActive))\n",
    "del(tmActive) # delete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7,  8, 14, 20])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build `spSDR[track[0]['sp_active']]` back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_active = np.zeros_like(spSDR[0])\n",
    "sp_active[tm_active] = 1\n",
    "sp_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the corresponding column in spSDR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching spSDR: [1]\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for _ in spSDR:\n",
    "    i =+ 1\n",
    "    if np.array_equal(sp_active, spSDR[_]) == True:\n",
    "        idx.append(i)\n",
    "print \"matching spSDR:\", idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap:  [0, 1, 2, 1, 0]\n",
      "InputSDR[idx]:  2\n",
      "inputSDR:  [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# calculate with which inputSDR, the active SP col has the higher overlap: \n",
    "\n",
    "\n",
    "for j in idx:\n",
    "    overlap = []\n",
    "    for i in xrange(len(track)):\n",
    "        overlap.append(sum(track[i]['inputSDR'] * spSDR[j]))\n",
    "        o = last_max_index(overlap)\n",
    "        \n",
    "    print \"overlap: \", str(overlap) +  \"\\nInputSDR[idx]: \", str(o)\n",
    "    print \"inputSDR: \", str(track[o]['inputSDR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should be useful in case we have ties in the overlap-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_back_SP_to_SDR(lista):\n",
    "    '''\n",
    "    This fnc returns the indeces of the InputSDR/s that match \n",
    "    (have the highest overalpping score) the current SP the most.\n",
    "    \n",
    "    input:  copy of a list `list[:]` with the overlap score bw. \n",
    "            the winning spSDR[i] and the inputSDR[0:]   \n",
    "    output: 'match', a list, indeces of InputSDR in `track`\n",
    "    '''\n",
    "    \n",
    "    a = max(lista)\n",
    "    b = a\n",
    "    match = []\n",
    "    count = 0\n",
    "\n",
    "    while b == a:\n",
    "        i = lista.index(b)\n",
    "        out = lista.pop(i)\n",
    "        i = i+count  # fill the indexes popped out\n",
    "        match.append(i)\n",
    "        count += 1\n",
    "        b = max(lista)    \n",
    "    \n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_back_SP_to_SDR(overlap[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputVal[2]: 76.12416182\n",
      "De-Encoder: ({'[70:80]': ([[76.111111111111114, 76.111111111111114]], '76.11')}, ['[70:80]'])\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for i in match_back_SP_to_SDR(overlap[:]):\n",
    "    print \"inputVal[\" + str(i) + \"]: \" + str(track[i]['inputVal'])\n",
    "    print \"De-Encoder: \" + str(vEnc.decode(track[i]['inputSDR']))\n",
    "    print \"-------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Parameters\n",
    "\n",
    "`MODEL_PARAMS` have all of the parameters for the CLA model and subcomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model Params!\n",
    "MODEL_PARAMS = {\n",
    "    # Type of model that the rest of these parameters apply to.\n",
    "    'model': \"HTMPrediction\",\n",
    "\n",
    "    # Version that specifies the format of the config.\n",
    "    'version': 1,\n",
    "\n",
    "    # Intermediate variables used to compute fields in modelParams and also\n",
    "    # referenced from the control section.\n",
    "    'aggregationInfo': {   'days': 0,\n",
    "        'fields': [('consumption', 'sum')],\n",
    "        'hours': 1,\n",
    "        'microseconds': 0,\n",
    "        'milliseconds': 0,\n",
    "        'minutes': 0,\n",
    "        'months': 0,\n",
    "        'seconds': 0,\n",
    "        'weeks': 0,\n",
    "        'years': 0},\n",
    "\n",
    "    'predictAheadTime': None,\n",
    "\n",
    "    # Model parameter dictionary.\n",
    "    'modelParams': {\n",
    "        # The type of inference that this model will perform\n",
    "        'inferenceType': 'TemporalMultiStep',\n",
    "\n",
    "        'sensorParams': {\n",
    "            # Sensor diagnostic output verbosity control;\n",
    "            # if > 0: sensor region will print out on screen what it's sensing\n",
    "            # at each step 0: silent; >=1: some info; >=2: more info;\n",
    "            # >=3: even more info (see compute() in py/regions/RecordSensor.py)\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # Include the encoders we use\n",
    "            'encoders': {\n",
    "                u'timestamp_timeOfDay': {\n",
    "                    'fieldname': u'timestamp',\n",
    "                    'name': u'timestamp_timeOfDay',\n",
    "                    'timeOfDay': (21, 0.5),\n",
    "                    'type': 'DateEncoder'\n",
    "                },\n",
    "                u'timestamp_dayOfWeek': None,\n",
    "                u'timestamp_weekend': None,\n",
    "                u'consumption': {\n",
    "                    'clipInput': True,\n",
    "                    'fieldname': u'consumption',\n",
    "                    'maxval': 100.0,\n",
    "                    'minval': 0.0,\n",
    "                    'n': 50,\n",
    "                    'name': u'c1',\n",
    "                    'type': 'ScalarEncoder',\n",
    "                    'w': 21\n",
    "                },\n",
    "            },\n",
    "\n",
    "            # A dictionary specifying the period for automatically-generated\n",
    "            # resets from a RecordSensor;\n",
    "            #\n",
    "            # None = disable automatically-generated resets (also disabled if\n",
    "            # all of the specified values evaluate to 0).\n",
    "            # Valid keys is the desired combination of the following:\n",
    "            #   days, hours, minutes, seconds, milliseconds, microseconds, weeks\n",
    "            #\n",
    "            # Example for 1.5 days: sensorAutoReset = dict(days=1,hours=12),\n",
    "            #\n",
    "            # (value generated from SENSOR_AUTO_RESET)\n",
    "            'sensorAutoReset' : None,\n",
    "        },\n",
    "\n",
    "        'spEnable': True,\n",
    "\n",
    "        'spParams': {\n",
    "            # SP diagnostic output verbosity control;\n",
    "            # 0: silent; >=1: some info; >=2: more info;\n",
    "            'spVerbosity' : 0,\n",
    "\n",
    "            # Spatial Pooler implementation selector, see getSPClass\n",
    "            # in py/regions/SPRegion.py for details\n",
    "            # 'py' (default), 'cpp' (speed optimized, new)\n",
    "            'spatialImp' : 'cpp',\n",
    "\n",
    "            'globalInhibition': 1,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            'inputWidth': 0,\n",
    "\n",
    "            # SP inhibition control (absolute value);\n",
    "            # Maximum number of active columns in the SP region's output (when\n",
    "            # there are more, the weaker ones are suppressed)\n",
    "            'numActiveColumnsPerInhArea': 40,\n",
    "\n",
    "            'seed': 1956,\n",
    "\n",
    "            # potentialPct\n",
    "            # What percent of the columns's receptive field is available\n",
    "            # for potential synapses. At initialization time, we will\n",
    "            # choose potentialPct * (2*potentialRadius+1)^2\n",
    "            'potentialPct': 0.5,\n",
    "\n",
    "            # The default connected threshold. Any synapse whose\n",
    "            # permanence value is above the connected threshold is\n",
    "            # a \"connected synapse\", meaning it can contribute to the\n",
    "            # cell's firing. Typical value is 0.10. Cells whose activity\n",
    "            # level before inhibition falls below minDutyCycleBeforeInh\n",
    "            # will have their own internal synPermConnectedCell\n",
    "            # threshold set below this default value.\n",
    "            # (This concept applies to both SP and TM and so 'cells'\n",
    "            # is correct here as opposed to 'columns')\n",
    "            'synPermConnected': 0.1,\n",
    "\n",
    "            'synPermActiveInc': 0.1,\n",
    "\n",
    "            'synPermInactiveDec': 0.005,\n",
    "        },\n",
    "\n",
    "        # Controls whether TM is enabled or disabled;\n",
    "        # TM is necessary for making temporal predictions, such as predicting\n",
    "        # the next inputs.  Without TP, the model is only capable of\n",
    "        # reconstructing missing sensor inputs (via SP).\n",
    "        'tmEnable' : True,\n",
    "\n",
    "        'tmParams': {\n",
    "            # TM diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            # (see verbosity in nupic/trunk/py/nupic/research/TP.py and BacktrackingTMCPP.py)\n",
    "            'verbosity': 0,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            # The number of cells (i.e., states), allocated per column.\n",
    "            'cellsPerColumn': 32,\n",
    "\n",
    "            'inputWidth': 2048,\n",
    "\n",
    "            'seed': 1960,\n",
    "\n",
    "            # Temporal Pooler implementation selector (see _getTPClass in\n",
    "            # CLARegion.py).\n",
    "            'temporalImp': 'cpp',\n",
    "\n",
    "            # New Synapse formation count\n",
    "            # NOTE: If None, use spNumActivePerInhArea\n",
    "            #\n",
    "            # TODO: need better explanation\n",
    "            'newSynapseCount': 20,\n",
    "\n",
    "            # Maximum number of synapses per segment\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSynapsesPerSegment': 32,\n",
    "\n",
    "            # Maximum number of segments per cell\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSegmentsPerCell': 128,\n",
    "\n",
    "            # Initial Permanence\n",
    "            # TODO: need better explanation\n",
    "            'initialPerm': 0.21,\n",
    "\n",
    "            # Permanence Increment\n",
    "            'permanenceInc': 0.1,\n",
    "\n",
    "            # Permanence Decrement\n",
    "            # If set to None, will automatically default to tpPermanenceInc\n",
    "            # value.\n",
    "            'permanenceDec' : 0.1,\n",
    "\n",
    "            'globalDecay': 0.0,\n",
    "\n",
    "            'maxAge': 0,\n",
    "\n",
    "            # Minimum number of active synapses for a segment to be considered\n",
    "            # during search for the best-matching segments.\n",
    "            # None=use default\n",
    "            # Replaces: tpMinThreshold\n",
    "            'minThreshold': 9,\n",
    "\n",
    "            # Segment activation threshold.\n",
    "            # A segment is active if it has >= tpSegmentActivationThreshold\n",
    "            # connected synapses that are active due to infActiveState\n",
    "            # None=use default\n",
    "            # Replaces: tpActivationThreshold\n",
    "            'activationThreshold': 12,\n",
    "\n",
    "            'outputType': 'normal',\n",
    "\n",
    "            # \"Pay Attention Mode\" length. This tells the TM how many new\n",
    "            # elements to append to the end of a learned sequence at a time.\n",
    "            # Smaller values are better for datasets with short sequences,\n",
    "            # higher values are better for datasets with long sequences.\n",
    "            'pamLength': 1,\n",
    "        },\n",
    "\n",
    "        'clParams': {\n",
    "            'regionName' : 'SDRClassifierRegion',\n",
    "\n",
    "            # Classifier diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # This controls how fast the classifier learns/forgets. Higher values\n",
    "            # make it adapt faster and forget older patterns faster.\n",
    "            'alpha': 0.005,\n",
    "\n",
    "            # This is set after the call to updateConfigFromSubConfig and is\n",
    "            # computed from the aggregationInfo and predictAheadTime.\n",
    "            'steps': '1,5',\n",
    "\n",
    "            'implementation': 'cpp',\n",
    "        },\n",
    "\n",
    "        'trainSPNetOnlyIfRequested': False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mleborgne/_git/nupic/src/nupic/datafiles/extra/hotgym/hotgym.csv\n",
      "\n",
      "gym,address,timestamp,consumption\n",
      "string,string,datetime,float\n",
      "S,,T,\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:00:00.0,5.3\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:15:00.0,5.5\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:30:00.0,5.1\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:45:00.0,5.3\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 01:00:00.0,5.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import resource_filename\n",
    "\n",
    "datasetPath = resource_filename(\"nupic.datafiles\", \"extra/hotgym/hotgym.csv\")\n",
    "print datasetPath\n",
    "\n",
    "with open(datasetPath) as inputFile:\n",
    "    print\n",
    "    for _ in xrange(8):\n",
    "        print inputFile.next().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loading Data\n",
    "\n",
    "`FileRecordStream` - file reader for the NuPIC file format (CSV with three header rows, understands datetimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 0), 5.3]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 15), 5.5]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 30), 5.1]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 45), 5.3]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 1, 0), 5.2]\n"
     ]
    }
   ],
   "source": [
    "from nupic.data.file_record_stream import FileRecordStream\n",
    "\n",
    "def getData():\n",
    "    return FileRecordStream(datasetPath)\n",
    "\n",
    "data = getData()\n",
    "for _ in xrange(5):\n",
    "    print data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.model_factory import ModelFactory\n",
    "model = ModelFactory.create(MODEL_PARAMS)\n",
    "model.enableInference({'predictedField': 'consumption'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  5.3\n",
      "prediction:  5.3\n",
      "input:  5.5\n",
      "prediction:  5.5\n",
      "input:  5.1\n",
      "prediction:  5.36\n",
      "input:  5.3\n",
      "prediction:  5.1\n",
      "input:  5.2\n",
      "prediction:  5.342\n",
      "input:  5.5\n",
      "prediction:  5.2994\n",
      "input:  4.5\n",
      "prediction:  5.35958\n",
      "input:  1.2\n",
      "prediction:  4.92\n",
      "input:  1.1\n",
      "prediction:  1.2\n",
      "input:  1.2\n",
      "prediction:  1.17\n",
      "input:  1.2\n",
      "prediction:  1.179\n",
      "input:  1.2\n",
      "prediction:  1.1853\n",
      "input:  1.2\n",
      "prediction:  1.18971\n",
      "input:  1.2\n",
      "prediction:  1.192797\n",
      "input:  1.1\n",
      "prediction:  1.1949579\n",
      "input:  1.2\n",
      "prediction:  1.16647053\n",
      "input:  1.1\n",
      "prediction:  1.176529371\n",
      "input:  1.2\n",
      "prediction:  1.1535705597\n",
      "input:  1.2\n",
      "prediction:  1.16749939179\n",
      "input:  1.1\n",
      "prediction:  1.17724957425\n",
      "input:  1.2\n",
      "prediction:  1.15407470198\n",
      "input:  6.0\n",
      "prediction:  1.16785229138\n",
      "input:  7.9\n",
      "prediction:  5.551706\n",
      "input:  8.4\n",
      "prediction:  6.2561942\n",
      "input:  10.6\n",
      "prediction:  6.89933594\n",
      "input:  12.4\n",
      "prediction:  10.6\n",
      "input:  12.1\n",
      "prediction:  12.4\n",
      "input:  12.4\n",
      "prediction:  12.31\n",
      "input:  11.4\n",
      "prediction:  12.337\n",
      "input:  11.2\n",
      "prediction:  10.84\n",
      "input:  10.8\n",
      "prediction:  10.948\n",
      "input:  12.0\n",
      "prediction:  10.9036\n",
      "input:  11.8\n",
      "prediction:  11.23252\n",
      "input:  11.9\n",
      "prediction:  11.402764\n",
      "input:  11.4\n",
      "prediction:  11.5519348\n",
      "input:  11.0\n",
      "prediction:  11.50635436\n",
      "input:  9.8\n",
      "prediction:  11.354448052\n",
      "input:  9.8\n",
      "prediction:  10.8881136364\n",
      "input:  10.8\n",
      "prediction:  10.5616795455\n",
      "input:  11.1\n",
      "prediction:  10.6331756818\n",
      "input:  11.1\n",
      "prediction:  10.7732229773\n",
      "input:  11.0\n",
      "prediction:  10.8712560841\n",
      "input:  10.7\n",
      "prediction:  10.9098792589\n",
      "input:  10.6\n",
      "prediction:  10.8469154812\n",
      "input:  10.3\n",
      "prediction:  10.7728408368\n",
      "input:  10.1\n",
      "prediction:  10.6309885858\n",
      "input:  12.9\n",
      "prediction:  10.4716920101\n",
      "input:  10.5\n",
      "prediction:  10.4716920101\n",
      "input:  9.7\n",
      "prediction:  10.480184407\n",
      "input:  9.7\n",
      "prediction:  10.2461290849\n",
      "input:  9.2\n",
      "prediction:  10.0822903594\n",
      "input:  9.2\n",
      "prediction:  9.81760325161\n",
      "input:  9.2\n",
      "prediction:  9.63232227613\n",
      "input:  9.3\n",
      "prediction:  9.50262559329\n",
      "input:  9.1\n",
      "prediction:  9.4418379153\n",
      "input:  9.0\n",
      "prediction:  9.33928654071\n",
      "input:  8.9\n",
      "prediction:  9.2375005785\n",
      "input:  9.0\n",
      "prediction:  9.13625040495\n",
      "input:  8.9\n",
      "prediction:  9.09537528346\n",
      "input:  8.9\n",
      "prediction:  9.03676269843\n",
      "input:  9.0\n",
      "prediction:  8.9957338889\n",
      "input:  9.2\n",
      "prediction:  8.99701372223\n",
      "input:  10.0\n",
      "prediction:  9.05790960556\n",
      "input:  10.7\n",
      "prediction:  9.34053672389\n",
      "input:  8.9\n",
      "prediction:  9.74837570672\n",
      "input:  9.0\n",
      "prediction:  9.49386299471\n",
      "input:  9.0\n",
      "prediction:  9.34570409629\n",
      "input:  9.3\n",
      "prediction:  9.24199286741\n",
      "input:  9.3\n",
      "prediction:  9.25939500718\n",
      "input:  9.1\n",
      "prediction:  9.27157650503\n",
      "input:  9.1\n",
      "prediction:  9.22010355352\n",
      "input:  9.1\n",
      "prediction:  9.18407248746\n",
      "input:  9.2\n",
      "prediction:  9.15885074122\n",
      "input:  9.4\n",
      "prediction:  9.17119551886\n",
      "input:  9.3\n",
      "prediction:  9.2398368632\n",
      "input:  9.3\n",
      "prediction:  9.25788580424\n",
      "input:  9.1\n",
      "prediction:  9.27052006297\n",
      "input:  9.1\n",
      "prediction:  9.21936404408\n",
      "input:  11.0\n",
      "prediction:  9.18355483085\n",
      "input:  9.0\n",
      "prediction:  9.7284883816\n",
      "input:  8.6\n",
      "prediction:  9.50994186712\n",
      "input:  3.0\n",
      "prediction:  9.50994186712\n",
      "input:  1.3\n",
      "prediction:  4.344\n",
      "input:  1.2\n",
      "prediction:  1.20749660397\n",
      "input:  1.3\n",
      "prediction:  1.20524762278\n",
      "input:  1.3\n",
      "prediction:  1.23367333594\n",
      "input:  1.3\n",
      "prediction:  1.25357133516\n",
      "input:  1.2\n",
      "prediction:  1.26749993461\n",
      "input:  1.3\n",
      "prediction:  1.24724995423\n",
      "input:  1.2\n",
      "prediction:  1.26307496796\n",
      "input:  1.3\n",
      "prediction:  1.24415247757\n",
      "input:  1.2\n",
      "prediction:  1.2609067343\n",
      "input:  1.3\n",
      "prediction:  1.24263471401\n",
      "input:  1.2\n",
      "prediction:  1.25984429981\n",
      "input:  1.1\n",
      "prediction:  1.24189100987\n",
      "input:  2.3\n",
      "prediction:  1.19932370691\n",
      "input:  5.5\n",
      "prediction:  3.7308\n",
      "input:  5.5\n",
      "prediction:  6.8366746106\n",
      "input:  5.8\n",
      "prediction:  6.43567222742\n",
      "input:  5.7\n",
      "prediction:  6.24497055919\n"
     ]
    }
   ],
   "source": [
    "data = getData()\n",
    "for _ in xrange(100):\n",
    "    record = dict(zip(data.getFieldNames(), data.next()))\n",
    "    print \"input: \", record[\"consumption\"]\n",
    "    result = model.run(record)\n",
    "    print \"prediction: \", result.inferences[\"multiStepBestPredictions\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-step prediction:  1.19932370691\n"
     ]
    }
   ],
   "source": [
    "print \"5-step prediction: \", result.inferences[\"multiStepBestPredictions\"][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model Params!\n",
    "MODEL_PARAMS = {\n",
    "    # Type of model that the rest of these parameters apply to.\n",
    "    'model': \"HTMPrediction\",\n",
    "\n",
    "    # Version that specifies the format of the config.\n",
    "    'version': 1,\n",
    "\n",
    "    # Intermediate variables used to compute fields in modelParams and also\n",
    "    # referenced from the control section.\n",
    "    'aggregationInfo': {   'days': 0,\n",
    "        'fields': [('consumption', 'sum')],\n",
    "        'hours': 1,\n",
    "        'microseconds': 0,\n",
    "        'milliseconds': 0,\n",
    "        'minutes': 0,\n",
    "        'months': 0,\n",
    "        'seconds': 0,\n",
    "        'weeks': 0,\n",
    "        'years': 0},\n",
    "\n",
    "    'predictAheadTime': None,\n",
    "\n",
    "    # Model parameter dictionary.\n",
    "    'modelParams': {\n",
    "        # The type of inference that this model will perform\n",
    "        'inferenceType': 'TemporalAnomaly',\n",
    "\n",
    "        'sensorParams': {\n",
    "            # Sensor diagnostic output verbosity control;\n",
    "            # if > 0: sensor region will print out on screen what it's sensing\n",
    "            # at each step 0: silent; >=1: some info; >=2: more info;\n",
    "            # >=3: even more info (see compute() in py/regions/RecordSensor.py)\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # Include the encoders we use\n",
    "            'encoders': {\n",
    "                u'timestamp_timeOfDay': {\n",
    "                    'fieldname': u'timestamp',\n",
    "                    'name': u'timestamp_timeOfDay',\n",
    "                    'timeOfDay': (21, 0.5),\n",
    "                    'type': 'DateEncoder'},\n",
    "                u'timestamp_dayOfWeek': None,\n",
    "                u'timestamp_weekend': None,\n",
    "                u'consumption': {\n",
    "                    'clipInput': True,\n",
    "                    'fieldname': u'consumption',\n",
    "                    'maxval': 100.0,\n",
    "                    'minval': 0.0,\n",
    "                    'n': 50,\n",
    "                    'name': u'c1',\n",
    "                    'type': 'ScalarEncoder',\n",
    "                    'w': 21},},\n",
    "\n",
    "            # A dictionary specifying the period for automatically-generated\n",
    "            # resets from a RecordSensor;\n",
    "            #\n",
    "            # None = disable automatically-generated resets (also disabled if\n",
    "            # all of the specified values evaluate to 0).\n",
    "            # Valid keys is the desired combination of the following:\n",
    "            #   days, hours, minutes, seconds, milliseconds, microseconds, weeks\n",
    "            #\n",
    "            # Example for 1.5 days: sensorAutoReset = dict(days=1,hours=12),\n",
    "            #\n",
    "            # (value generated from SENSOR_AUTO_RESET)\n",
    "            'sensorAutoReset' : None,\n",
    "        },\n",
    "\n",
    "        'spEnable': True,\n",
    "\n",
    "        'spParams': {\n",
    "            # SP diagnostic output verbosity control;\n",
    "            # 0: silent; >=1: some info; >=2: more info;\n",
    "            'spVerbosity' : 0,\n",
    "\n",
    "            # Spatial Pooler implementation selector, see getSPClass\n",
    "            # in py/regions/SPRegion.py for details\n",
    "            # 'py' (default), 'cpp' (speed optimized, new)\n",
    "            'spatialImp' : 'cpp',\n",
    "\n",
    "            'globalInhibition': 1,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            'inputWidth': 0,\n",
    "\n",
    "            # SP inhibition control (absolute value);\n",
    "            # Maximum number of active columns in the SP region's output (when\n",
    "            # there are more, the weaker ones are suppressed)\n",
    "            'numActiveColumnsPerInhArea': 40,\n",
    "\n",
    "            'seed': 1956,\n",
    "\n",
    "            # potentialPct\n",
    "            # What percent of the columns's receptive field is available\n",
    "            # for potential synapses. At initialization time, we will\n",
    "            # choose potentialPct * (2*potentialRadius+1)^2\n",
    "            'potentialPct': 0.5,\n",
    "\n",
    "            # The default connected threshold. Any synapse whose\n",
    "            # permanence value is above the connected threshold is\n",
    "            # a \"connected synapse\", meaning it can contribute to the\n",
    "            # cell's firing. Typical value is 0.10. Cells whose activity\n",
    "            # level before inhibition falls below minDutyCycleBeforeInh\n",
    "            # will have their own internal synPermConnectedCell\n",
    "            # threshold set below this default value.\n",
    "            # (This concept applies to both SP and TM and so 'cells'\n",
    "            # is correct here as opposed to 'columns')\n",
    "            'synPermConnected': 0.1,\n",
    "\n",
    "            'synPermActiveInc': 0.1,\n",
    "\n",
    "            'synPermInactiveDec': 0.005,\n",
    "        },\n",
    "\n",
    "        # Controls whether TM is enabled or disabled;\n",
    "        # TM is necessary for making temporal predictions, such as predicting\n",
    "        # the next inputs.  Without TP, the model is only capable of\n",
    "        # reconstructing missing sensor inputs (via SP).\n",
    "        'tmEnable' : True,\n",
    "\n",
    "        'tmParams': {\n",
    "            # TM diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            # (see verbosity in nupic/trunk/py/nupic/research/TP.py and BacktrackingTMCPP.py)\n",
    "            'verbosity': 0,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            # The number of cells (i.e., states), allocated per column.\n",
    "            'cellsPerColumn': 32,\n",
    "\n",
    "            'inputWidth': 2048,\n",
    "\n",
    "            'seed': 1960,\n",
    "\n",
    "            # Temporal Pooler implementation selector (see _getTPClass in\n",
    "            # CLARegion.py).\n",
    "            'temporalImp': 'cpp',\n",
    "\n",
    "            # New Synapse formation count\n",
    "            # NOTE: If None, use spNumActivePerInhArea\n",
    "            #\n",
    "            # TODO: need better explanation\n",
    "            'newSynapseCount': 20,\n",
    "\n",
    "            # Maximum number of synapses per segment\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSynapsesPerSegment': 32,\n",
    "\n",
    "            # Maximum number of segments per cell\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSegmentsPerCell': 128,\n",
    "\n",
    "            # Initial Permanence\n",
    "            # TODO: need better explanation\n",
    "            'initialPerm': 0.21,\n",
    "\n",
    "            # Permanence Increment\n",
    "            'permanenceInc': 0.1,\n",
    "\n",
    "            # Permanence Decrement\n",
    "            # If set to None, will automatically default to tpPermanenceInc\n",
    "            # value.\n",
    "            'permanenceDec' : 0.1,\n",
    "\n",
    "            'globalDecay': 0.0,\n",
    "\n",
    "            'maxAge': 0,\n",
    "\n",
    "            # Minimum number of active synapses for a segment to be considered\n",
    "            # during search for the best-matching segments.\n",
    "            # None=use default\n",
    "            # Replaces: tpMinThreshold\n",
    "            'minThreshold': 9,\n",
    "\n",
    "            # Segment activation threshold.\n",
    "            # A segment is active if it has >= tpSegmentActivationThreshold\n",
    "            # connected synapses that are active due to infActiveState\n",
    "            # None=use default\n",
    "            # Replaces: tpActivationThreshold\n",
    "            'activationThreshold': 12,\n",
    "\n",
    "            'outputType': 'normal',\n",
    "\n",
    "            # \"Pay Attention Mode\" length. This tells the TM how many new\n",
    "            # elements to append to the end of a learned sequence at a time.\n",
    "            # Smaller values are better for datasets with short sequences,\n",
    "            # higher values are better for datasets with long sequences.\n",
    "            'pamLength': 1,\n",
    "        },\n",
    "\n",
    "        'clParams': {\n",
    "            'regionName' : 'SDRClassifierRegion',\n",
    "\n",
    "            # Classifier diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # This controls how fast the classifier learns/forgets. Higher values\n",
    "            # make it adapt faster and forget older patterns faster.\n",
    "            'alpha': 0.005,\n",
    "\n",
    "            # This is set after the call to updateConfigFromSubConfig and is\n",
    "            # computed from the aggregationInfo and predictAheadTime.\n",
    "            'steps': '1',\n",
    "\n",
    "            'implementation': 'cpp',\n",
    "        },\n",
    "\n",
    "        'anomalyParams': {\n",
    "            u'anomalyCacheRecords': None,\n",
    "            u'autoDetectThreshold': None,\n",
    "            u'autoDetectWaitRecords': 2184\n",
    "        },\n",
    "\n",
    "        'trainSPNetOnlyIfRequested': False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.model_factory import ModelFactory\n",
    "model = ModelFactory.create(MODEL_PARAMS)\n",
    "model.enableInference({'predictedField': 'consumption'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  5.3\n",
      "prediction:  5.3\n",
      "input:  5.5\n",
      "prediction:  5.5\n",
      "input:  5.1\n",
      "prediction:  5.36\n",
      "input:  5.3\n",
      "prediction:  5.1\n",
      "input:  5.2\n",
      "prediction:  5.342\n"
     ]
    }
   ],
   "source": [
    "data = getData()\n",
    "for _ in xrange(5):\n",
    "    record = dict(zip(data.getFieldNames(), data.next()))\n",
    "    print \"input: \", record[\"consumption\"]\n",
    "    result = model.run(record)\n",
    "    print \"prediction: \", result.inferences[\"multiStepBestPredictions\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResult(\tpredictionNumber=4\n",
      "\trawInput={'timestamp': datetime.datetime(2010, 7, 2, 1, 0), 'gym': 'Balgowlah Platinum', 'consumption': 5.2, 'address': 'Shop 67 197-215 Condamine Street Balgowlah 2093'}\n",
      "\tsensorInput=SensorInput(\tdataRow=(5.2, 1.0)\n",
      "\tdataDict={'timestamp': datetime.datetime(2010, 7, 2, 1, 0), 'gym': 'Balgowlah Platinum', 'consumption': 5.2, 'address': 'Shop 67 197-215 Condamine Street Balgowlah 2093'}\n",
      "\tdataEncodings=[array([ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32), array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)]\n",
      "\tsequenceReset=0.0\n",
      "\tcategory=-1\n",
      ")\n",
      "\tinferences={'multiStepPredictions': {1: {5.1: 0.0088801263517415546, 5.2: 0.010775254623541418, 5.341999999999999: 0.98034461902471692}}, 'multiStepBucketLikelihoods': {1: {1: 0.0088801263517415546, 2: 0.98034461902471692}}, 'multiStepBestPredictions': {1: 5.341999999999999}, 'anomalyLabel': '[]', 'anomalyScore': 0.40000001}\n",
      "\tmetrics=None\n",
      "\tpredictedFieldIdx=0\n",
      "\tpredictedFieldName=consumption\n",
      "\tclassifierInput=ClassifierInput(\tdataRow=5.2\n",
      "\tbucketIndex=2\n",
      ")\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly score:  0.4\n"
     ]
    }
   ],
   "source": [
    "print \"anomaly score: \", result.inferences[\"anomalyScore\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__See Subutai's talk for more info on anomaly detection!__\n",
    "\n",
    "# Built-in OPF Clients\n",
    "\n",
    "`python examples/opf/bin/OpfRunExperiment.py examples/opf/experiments/multistep/hotgym/`\n",
    "\n",
    "Outputs `examples/opf/experiments/multistep/hotgym/inference/DefaultTask.TemporalMultiStep.predictionLog.csv`\n",
    "\n",
    "`python bin/run_swarm.py examples/opf/experiments/multistep/hotgym/permutations.py`\n",
    "\n",
    "Outputs `examples/opf/experiments/multistep/hotgym/model_0/description.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nupic",
   "language": "python",
   "name": "nupic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
